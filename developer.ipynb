{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?f_E=2&f_TPR=r604800&keywords=\"data engineer\"&location=St Louis, Missouri, United States&start=0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import oracledb\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "title = 'data engineer'\n",
    "location = \"St Louis, Missouri, United States\" \n",
    "#location = \"United States\" \n",
    "job_count = 0\n",
    "exp_level = \"2\"  # 2==entry level\n",
    "post_date = \"r604800\"  # r604800==Past week\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
    "\n",
    "base_url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\"\n",
    "url = f'{base_url}?f_E={exp_level}&f_TPR={post_date}&keywords=\"{title}\"&location={location}&start={job_count}'\n",
    "\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends a request for one results page to LinkedIn to get a list of job titles\n",
    "def get_jobs_page(job_count) -> list:\n",
    "    url = f'{base_url}?f_E={exp_level}&f_TPR={post_date}&keywords=\"{title}\"&location={location}&start={job_count}'\n",
    "    print(\"job page URL: \", url)\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    all_job_titles = soup.find_all(\"li\")\n",
    "    return all_job_titles\n",
    "\n",
    "# Parses out the job title from one listing\n",
    "def parse_job_id(job):\n",
    "    return job.find(\"div\", {\"class\":\"base-card\"}).get(\"data-entity-urn\").split(\":\")[3]\n",
    "\n",
    "# Get all job ids from one results page\n",
    "def get_job_ids(job_count):\n",
    "    job_ids = []\n",
    "    all_job_titles = get_jobs_page(job_count)\n",
    "    if not all_job_titles:  # if no jobs titles in the list\n",
    "        print(\"No job titles found!\")\n",
    "        return None \n",
    "\n",
    "    all_job_ids = list(map(parse_job_id, all_job_titles))\n",
    "    print(\"all job ids: \", all_job_ids)\n",
    "    return all_job_ids\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# I can't figure out how to get the count, the below function is useless\n",
    "def get_result_count():\n",
    "\n",
    "    base_url = \"https://www.linkedin.com/jobs/search\"\n",
    "    url = f'{base_url}?f_E={exp_level}&f_TPR={post_date}&keywords=\"{title}\"&location={location}'\n",
    "    print(url)\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    print(soup)\n",
    "    count = soup.find(\"div\", {\"class\":\"jobs-search-results-list__subtitle\"})\n",
    "    print(count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job page URL:  https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?f_E=2&f_TPR=r604800&keywords=\"data engineer\"&location=St Louis, Missouri, United States&start=0\n",
      "all job ids:  ['3708952912', '3714572531']\n",
      "['3708952912', '3714572531']\n"
     ]
    }
   ],
   "source": [
    "job_ids = []\n",
    "job_count = 0\n",
    "max_jobs_to_scrape = 25\n",
    "# I can't get a job_count for the search query, \n",
    "# so going to scrape till it can NOT find any more job ids\n",
    "# or I'm going to scrape upto 300 jobs or 12 pages\n",
    "while job_count < max_jobs_to_scrape:\n",
    "    page_of_ids = get_job_ids(job_count)\n",
    "    if page_of_ids:\n",
    "        job_ids.extend(page_of_ids)\n",
    "    else:\n",
    "        break\n",
    "    job_count += 25\n",
    "    \n",
    "print(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(job_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/3708952912\n",
      "https://www.linkedin.com/jobs/view/tax-digital-transformation-innovation-senior-data-engineer-at-bdo-usa-3708952912?trk=public_jobs_topcard-title\n",
      "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/3714572531\n",
      "https://www.linkedin.com/jobs/view/data-scientist-with-security-clearance-at-clearancejobs-3714572531?trk=public_jobs_topcard-title\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>experience</th>\n",
       "      <th>Seniority_level</th>\n",
       "      <th>Employment_type</th>\n",
       "      <th>Job_function</th>\n",
       "      <th>Industries</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3708952912</td>\n",
       "      <td>BDO USA</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>Tax Digital Transformation &amp; Innovation Senior...</td>\n",
       "      <td>\\n\\nJob Description\\nJob Summary:\\nThe Digital...</td>\n",
       "      <td>Bachelor's degree and six (6) or more years o...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Finance and Accounting/Auditing</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>2023-09-09 01:21:20.675585</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/tax-digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3714572531</td>\n",
       "      <td>ClearanceJobs</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>Data Scientist with Security Clearance</td>\n",
       "      <td>\\n        Job Number: R0179261 Data Scientist\\...</td>\n",
       "      <td>The Opportunity: Ever-expanding technology lik...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Defense and Space Manufacturing</td>\n",
       "      <td>2023-09-07 01:21:21.359583</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id        company      location   \n",
       "0  3708952912        BDO USA  St Louis, MO  \\\n",
       "1  3714572531  ClearanceJobs  St Louis, MO   \n",
       "\n",
       "                                           job_title   \n",
       "0  Tax Digital Transformation & Innovation Senior...  \\\n",
       "1             Data Scientist with Security Clearance   \n",
       "\n",
       "                                     job_description   \n",
       "0  \\n\\nJob Description\\nJob Summary:\\nThe Digital...  \\\n",
       "1  \\n        Job Number: R0179261 Data Scientist\\...   \n",
       "\n",
       "                                          experience Seniority_level   \n",
       "0   Bachelor's degree and six (6) or more years o...     Entry level  \\\n",
       "1  The Opportunity: Ever-expanding technology lik...     Entry level   \n",
       "\n",
       "  Employment_type                            Job_function   \n",
       "0       Full-time         Finance and Accounting/Auditing  \\\n",
       "1       Part-time  Engineering and Information Technology   \n",
       "\n",
       "                        Industries               posting_date   \n",
       "0                       Accounting 2023-09-09 01:21:20.675585  \\\n",
       "1  Defense and Space Manufacturing 2023-09-07 01:21:21.359583   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.linkedin.com/jobs/view/tax-digital...  \n",
       "1  https://www.linkedin.com/jobs/view/data-scient...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_url = 'https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}'\n",
    "l_all_job_info = []\n",
    "\n",
    "for id in job_ids:\n",
    "    d_job_info = {}\n",
    "    d_job_info[\"job_id\"] = id\n",
    "    job_desc_url = job_url.format(id)\n",
    "    print(job_desc_url)\n",
    "    res = requests.get(job_desc_url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    \n",
    "    # Get the company name\n",
    "    d_job_info[\"company\"] = soup.find(\"div\", {\"class\":\"top-card-layout__card\"}).find(\"a\").find(\"img\").get(\"alt\")\n",
    "\n",
    "    # Get the location\n",
    "    d_job_info[\"location\"] = soup.find(\"div\", {\"class\":\"topcard__flavor-row\"}).find(\"span\", {\"class\":\"topcard__flavor--bullet\"}).text.strip()\n",
    "\n",
    "    # Get the job title\n",
    "    d_job_info[\"job_title\"] = soup.find(\"h2\", {\"class\":\"top-card-layout__title\"}).text.strip()\n",
    "\n",
    "    # Get the full job description \n",
    "    d_job_info[\"job_description\"] = soup.find(\"div\", {\"class\":\"show-more-less-html__markup\"}).get_text(separator=u\"\\n\")\n",
    "    \n",
    "    # Get years of experience!!!\n",
    "    d_job_info[\"experience\"] = re.findall(r\".*\\D\\d{1,2}\\D.*years?\", d_job_info[\"job_description\"])\n",
    "    d_job_info[\"experience\"] = \"\\n\".join(d_job_info[\"experience\"])\n",
    "\n",
    "    # Get Seniority level, Employment type, Job function, Industries\n",
    "    job_criteria_list = soup.find(\"ul\", {\"class\":\"description__job-criteria-list\"}).find_all(\"li\")\n",
    "    for criteria in job_criteria_list:\n",
    "        criteria = criteria.text.split(\"\\n\") # convert lines to a list\n",
    "        criteria = [i.strip() for i in criteria if i.strip()] # remove lines with only white space\n",
    "        criteria[0] = criteria[0].replace(\" \", \"_\")\n",
    "        d_job_info.update({criteria[0]:criteria[1]})\n",
    "\n",
    "    # Get job posting date\n",
    "    posting_date = soup.find(\"span\", {\"class\":\"posted-time-ago__text\"}).text.strip()\n",
    "    posting_num = int(re.match(r'\\d{1,2}',posting_date).group())\n",
    "    if \"minute\" in posting_date:\n",
    "        d_job_info[\"posting_date\"] = datetime.today() - timedelta(minutes=posting_num)\n",
    "    elif \"hour\" in posting_date:\n",
    "        d_job_info[\"posting_date\"] = datetime.today() - timedelta(hours=posting_num)\n",
    "    elif \"day\" in posting_date:\n",
    "        d_job_info[\"posting_date\"] = datetime.today() - timedelta(days=posting_num)\n",
    "    else:\n",
    "        d_job_info[\"posting_date\"] = \"\"\n",
    "    \n",
    "    \n",
    "    # !!! Get Other useful info with AI !!!\n",
    "\n",
    "    \n",
    "    # Get URL \n",
    "    d_job_info[\"url\"] = soup.find(\"a\", {\"class\":\"topcard__link\"}).get(\"href\")\n",
    "    print(d_job_info[\"url\"])\n",
    "\n",
    "    # Append the job info (dict) to the list of job info\n",
    "    l_all_job_info.append(d_job_info)\n",
    "\n",
    "# Convert list of all job info dicts to a dataframe\n",
    "df_all_job_info = pd.DataFrame(l_all_job_info)\n",
    "df_all_job_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 'test company', 'pleasentville', 'job_title', 'job description', 'experience', 'entry-level', 'full time', 'job function junction', 'pimpin', datetime.datetime(2023, 9, 10, 0, 0), 'www.pimpinainteasy.com')\n"
     ]
    }
   ],
   "source": [
    "# Oracle Connection string\n",
    "cs = '''(description= (retry_count=20)(retry_delay=3)(address=(protocol=tcps)(port=1521)(host=adb.us-sanjose-1.oraclecloud.com))(connect_data=(service_name=ga3e236c6957ba6_oltpdb_high.adb.oraclecloud.com))(security=(ssl_server_dn_match=yes)))'''\n",
    "\n",
    "connection = oracledb.connect(\n",
    "    user=\"appuser\",\n",
    "    password=os.environ['ORACLE_PASSWORD_APPUSER'],\n",
    "    dsn = cs\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM tbl_jobs\")\n",
    "results = cursor.fetchall()\n",
    "\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "# Close the cursor\n",
    "cursor.close()\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = '''(description= (retry_count=20)(retry_delay=3)(address=(protocol=tcps)(port=1521)(host=adb.us-sanjose-1.oraclecloud.com))(connect_data=(service_name=ga3e236c6957ba6_oltpdb_high.adb.oraclecloud.com))(security=(ssl_server_dn_match=yes)))'''\n",
    "\n",
    "connection = oracledb.connect(\n",
    "    user=\"appuser\",\n",
    "    password=os.environ['ORACLE_PASSWORD_APPUSER'],\n",
    "    dsn = cs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>experience</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9999</td>\n",
       "      <td>test company</td>\n",
       "      <td>pleasentville</td>\n",
       "      <td>job_title</td>\n",
       "      <td>job description</td>\n",
       "      <td>experience</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>full time</td>\n",
       "      <td>job function junction</td>\n",
       "      <td>pimpin</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>www.pimpinainteasy.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id       company       location  job_title  job_description   \n",
       "0    9999  test company  pleasentville  job_title  job description  \\\n",
       "\n",
       "   experience seniority_level employment_type           job_function   \n",
       "0  experience     entry-level       full time  job function junction  \\\n",
       "\n",
       "  industries posting_date                     url  \n",
       "0     pimpin   2023-09-10  www.pimpinainteasy.com  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=\"appuser\"\n",
    "password=os.environ['ORACLE_PASSWORD_APPUSER']\n",
    "engine = create_engine(\n",
    "    f'oracle+oracledb://{user}:{password}@{cs}'\n",
    "    )\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_jobs_from_db = pd.read_sql_query('SELECT * FROM tbl_jobs', conn)\n",
    "               \n",
    "df_jobs_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
